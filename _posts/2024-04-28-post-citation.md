---
layout: post
title: Second-order inquiries on statistics
date: 2024-11-09
tags: Philosophy, Statistics
categories: Thoughts
citation: true
---

> This article is originally written in Chinese. It was translated into English by ChatGPT and refined by the author. You can also see the Chinese version [here](https://zhuanlan.zhihu.com/p/5990531684).

Wikipedia defines statistics as "the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data". However, as a Ph.D. student in statistics and a philosophy enthusiast, I find this definition quite unsatisfactory. It is overly verbose, vague, and lacks precision. For instance, what does it mean to organize data? What does it mean to analyze it? By this definition, database principles should also fall under the umbrella of statistics, yet their methodologies differ significantly from what we recognize as statistical practice. Furthermore, is statistics truly a science? According to [Karl Popper’s](https://en.wikipedia.org/wiki/Karl_Popper) criteria, statistics doesn’t quite fit the definition of a science. This realization has prompted me to examine what statistics truly is and to pose a series of deeper, second-order questions about its nature.

Statistics occupies a unique position; it is neither like mathematics and logic, which fall under the category of [formalsciences]([https://zhida.zhihu.com/search?content_id=650090079&content_type=Answer&match_order=1&q=%E5%BD%A2%E5%BC%8F%E7%A7%91%E5%AD%A6&zhida_source=entity](https://en.wikipedia.org/wiki/Formal_science)), deriving new truths from existing true propositions through deductive reasoning, nor is it like the natural sciences, such as physics or chemistry, which use inductive reasoning to derive knowledge about the world from observations. From my perspective, statistics tries to answer a fundamental question in our knowledge: how can we preserve the va-
lidity of inductive reasoning? If I were to define statistics, I would call it **the study of inductive reasoning**.

Statistics tries to find optimal “inductive strategies” with desirable "deductive qualities", and that’s why we attach importance to aspects such as unbiasedness, invariance, and asymptotic normality.

Statistics is not a subset of mathematics, as many of its methods do not emerge solely from pure deductive reasoning. Its relationship with mathematics resembles that of physics with mathematics: both use mathematics as a tool to address problems within their own domains. But the research paradigm of statistics differs greatly from that of physics. Statistics tries to find optimal “inductive strategies” with desirable "deductive qualities", and that’s why we attach importance to aspects such as unbiasedness, invariance, and asymptotic normality.

The inherent unreliability of inductive reasoning is a fundamental flaw. Even if we observe a thousand black crows, we cannot conclusively state that "all crows are black." However, using statistical tools, we can assert "with over 95% confidence that we believe all crows in the world are black." We manage to draw reliable conclusions from inherently unreliable inductive data!

Of course, this assurance comes at a price, as statistical inference is always based on an unverifiable assumption: that the data originates from some "probability distribution." This raises an interesting question in the philosophy of science: realism or instrumentalism? Realism holds that scientific theories should reflect reality, while instrumentalism merely requires that they offer explanations and predictions. For example, is "gravity" an actual force present in the objective world, or is it just a model physicists use to describe our world? Most people would favor the former, though proving this philosophically is non-trivial. In contrast, many people adopt an instrumentalist approach to quantum theory, caring less about whether quantum states are "physical realities" and treating the theory as merely a "predictive tool"—in other words, "shut up and calculate."

In the case of statistics, few people concern themselves with whether statistical models represent any "physical reality." Among those who do, hardly any hold a realist stance. Some may view normal distributions or linear models as the "real-world mechanisms" generating data. But no one believes random forests or neural networks "exist" in any ontological sense; they are simply tools for making predictions. Going further, we often derive identical mathematical structures in statistics from completely different views on reality. For example, principal component analysis (PCA) can be viewed as maximizing data variance or as minimizing the distance between data points and a linear subspace; it can even be derived from game theory (an astonishing coincidence—or is it?). What does it mean, philosophically, that identical structures emerge from different perspectives on reality? Unlike the natural sciences, statistics is highly instrumentalist, and this abandonment of realism has yielded models with remarkable predictive power, such as deep learning. George Box’s famous saying, "All models are wrong, but some are useful," perfectly encapsulates this instrumentalist outlook.

On a deeper level, many interesting questions arise. Since statistics is the study of inductive reasoning, it must be closely related to epistemology in philosophy. Statistics uses mathematics and models to construct a framework for understanding the objective world. In frequentist theory, we often assume there exist some underlying "true" parameters and models underlying the data, and our task is to use data to approximate this "truth." This assertion, however, is open to question: Do these "true" parameters and models truly exist? What does "truth" mean? Is the objective world knowable? If so, to what extent? Readers familiar with philosophy will immediately recognize these as classic epistemological questions. In fact, such questions were thoroughly discussed and largely settled in Kant’s era, and these philosophical conclusions, in a certain sense, align well with the fundamental ideas in statistics.